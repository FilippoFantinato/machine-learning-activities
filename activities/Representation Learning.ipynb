{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOj2ySyZM0o30bo6JgWeKQP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## W2V on the WIKIPEDIA dataset"],"metadata":{"id":"-K-Nr4W5h_OJ"}},{"cell_type":"code","source":["import io\n","import re\n","import string\n","import tqdm\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"],"metadata":{"id":"cz7iVdBzgTy1","executionInfo":{"status":"aborted","timestamp":1669804990272,"user_tz":-60,"elapsed":21,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generates skip-gram pairs with negative sampling for a list of sequences\n","# (int-encoded sentences) based on window size, number of negative samples\n","# and vocabulary size.\n","def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n","  # Elements of each training example are appended to these lists.\n","  targets, contexts, labels = [], [], []\n","\n","  # Build the sampling table for `vocab_size` tokens.\n","  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n","\n","  # Iterate over all sequences (sentences) in the dataset.\n","  for sequence in tqdm.tqdm(sequences):\n","\n","    # Generate positive skip-gram pairs for a sequence (sentence).\n","    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n","          sequence,\n","          vocabulary_size=vocab_size,\n","          sampling_table=sampling_table,\n","          window_size=window_size,\n","          negative_samples=0)\n","\n","    # Iterate over each positive skip-gram pair to produce training examples\n","    # with a positive context word and negative samples.\n","    for target_word, context_word in positive_skip_grams:\n","      context_class = tf.expand_dims(\n","          tf.constant([context_word], dtype=\"int64\"), 1)\n","      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n","          true_classes=context_class,\n","          num_true=1,\n","          num_sampled=num_ns,\n","          unique=True,\n","          range_max=vocab_size,\n","          seed=seed,\n","          name=\"negative_sampling\")\n","\n","      # Build context and label vectors (for one target word)\n","      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n","      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n","\n","      # Append each element from the training example to global lists.\n","      targets.append(target_word)\n","      contexts.append(context)\n","      labels.append(label)\n","\n","  return targets, contexts, labels"],"metadata":{"id":"wkDmASzmgKWV","executionInfo":{"status":"aborted","timestamp":1669804990273,"user_tz":-60,"elapsed":21,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"metadata":{"id":"VyFQsZp2gZQn","executionInfo":{"status":"aborted","timestamp":1669804990274,"user_tz":-60,"elapsed":21,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path_to_file) as f:\n","  lines = f.read().splitlines()\n","for line in lines[:20]:\n","  print(line)"],"metadata":{"id":"lPC92xAWgamF","executionInfo":{"status":"aborted","timestamp":1669804990274,"user_tz":-60,"elapsed":21,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"],"metadata":{"id":"XOiFZCoogf_y","executionInfo":{"status":"aborted","timestamp":1669804990275,"user_tz":-60,"elapsed":22,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now, create a custom standardization function to lowercase the text and\n","# remove punctuation.\n","def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  return tf.strings.regex_replace(lowercase,\n","                                  '[%s]' % re.escape(string.punctuation), '')\n","\n","\n","# Define the vocabulary size and the number of words in a sequence.\n","vocab_size = 4096\n","sequence_length = 10\n","\n","# Use the `TextVectorization` layer to normalize, split, and map strings to\n","# integers. Set the `output_sequence_length` length to pad all samples to the\n","# same length.\n","vectorize_layer = layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)"],"metadata":{"id":"cR5g43Gbghus","executionInfo":{"status":"aborted","timestamp":1669804990276,"user_tz":-60,"elapsed":23,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.adapt(text_ds.batch(1024))"],"metadata":{"id":"TNXI3Wypgjh1","executionInfo":{"status":"aborted","timestamp":1669804990277,"user_tz":-60,"elapsed":24,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the created vocabulary for reference.\n","inverse_vocab = vectorize_layer.get_vocabulary()\n","print(inverse_vocab[:20])"],"metadata":{"id":"gU4Q7ClqglVO","executionInfo":{"status":"aborted","timestamp":1669804990278,"user_tz":-60,"elapsed":24,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorize the data in text_ds.\n","text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"],"metadata":{"id":"kUlsDQ3KglQO","executionInfo":{"status":"aborted","timestamp":1669804990280,"user_tz":-60,"elapsed":26,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequences = list(text_vector_ds.as_numpy_iterator())\n","print(len(sequences))"],"metadata":{"id":"Ae-ul14hgna-","executionInfo":{"status":"aborted","timestamp":1669804990281,"user_tz":-60,"elapsed":27,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for seq in sequences[:5]:\n","  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"],"metadata":{"id":"MiEQRlHwgpzd","executionInfo":{"status":"aborted","timestamp":1669804990282,"user_tz":-60,"elapsed":26,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["targets, contexts, labels = generate_training_data(\n","    sequences=sequences,\n","    window_size=2,\n","    num_ns=4,\n","    vocab_size=vocab_size,\n","    seed=SEED)\n","\n","targets = np.array(targets)\n","contexts = np.array(contexts)\n","labels = np.array(labels)\n","\n","print('\\n')\n","print(f\"targets.shape: {targets.shape}\")\n","print(f\"contexts.shape: {contexts.shape}\")\n","print(f\"labels.shape: {labels.shape}\")"],"metadata":{"id":"9fcAV4m3gqFH","executionInfo":{"status":"aborted","timestamp":1669804990282,"user_tz":-60,"elapsed":26,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 1024\n","BUFFER_SIZE = 10000\n","dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print(dataset)"],"metadata":{"id":"DtGUDySegtqS","executionInfo":{"status":"aborted","timestamp":1669804990283,"user_tz":-60,"elapsed":26,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","print(dataset)"],"metadata":{"id":"si5I0bRVgvzN","executionInfo":{"status":"aborted","timestamp":1669804990284,"user_tz":-60,"elapsed":27,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_ns = 4\n","\n","\n","class Word2Vec(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim):\n","    super(Word2Vec, self).__init__()\n","    self.target_embedding = layers.Embedding(vocab_size,\n","                                      embedding_dim,\n","                                      input_length=1,\n","                                      name=\"w2v_embedding\")\n","    self.context_embedding = layers.Embedding(vocab_size,\n","                                       embedding_dim,\n","                                       input_length=num_ns+1)\n","\n","  def call(self, pair):\n","    target, context = pair\n","    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n","    # context: (batch, context)\n","    if len(target.shape) == 2:\n","      target = tf.squeeze(target, axis=1)\n","    # target: (batch,)\n","    word_emb = self.target_embedding(target)\n","    # word_emb: (batch, embed)\n","    context_emb = self.context_embedding(context)\n","    # context_emb: (batch, context, embed)\n","    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n","    # dots: (batch, context)\n","    return dots"],"metadata":{"id":"oI_7xwx6gxV0","executionInfo":{"status":"aborted","timestamp":1669804990284,"user_tz":-60,"elapsed":27,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 128\n","word2vec = Word2Vec(vocab_size, embedding_dim)\n","word2vec.compile(optimizer='adam',\n","                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","                 metrics=['accuracy'])"],"metadata":{"id":"I5Dh5L2_g2J9","executionInfo":{"status":"aborted","timestamp":1669804990285,"user_tz":-60,"elapsed":434317,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"],"metadata":{"id":"pt86barbg3bk","executionInfo":{"status":"aborted","timestamp":1669804990286,"user_tz":-60,"elapsed":434315,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"],"metadata":{"id":"mXzpXwrlg5R7","executionInfo":{"status":"aborted","timestamp":1669804990286,"user_tz":-60,"elapsed":434309,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n","vocab = vectorize_layer.get_vocabulary()"],"metadata":{"id":"OvaQyUHxg6_o","executionInfo":{"status":"aborted","timestamp":1669804990287,"user_tz":-60,"elapsed":434308,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n","out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n","\n","for index, word in enumerate(vocab):\n","  if index == 0:\n","    continue  # skip 0, it's padding.\n","  vec = weights[index]\n","  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n","  out_m.write(word + \"\\n\")\n","out_v.close()\n","out_m.close()"],"metadata":{"id":"grfARe1Mg-sG","executionInfo":{"status":"aborted","timestamp":1669804990287,"user_tz":-60,"elapsed":434306,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","  from google.colab import files\n","  files.download('vectors.tsv')\n","  files.download('metadata.tsv')\n","except Exception:\n","  pass"],"metadata":{"id":"OuRiys6QhAM7","executionInfo":{"status":"aborted","timestamp":1669804990288,"user_tz":-60,"elapsed":434300,"user":{"displayName":"Filippo Fantinato","userId":"09233996461564846757"}}},"execution_count":null,"outputs":[]}]}